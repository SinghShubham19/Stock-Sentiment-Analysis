{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4bbacc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>A 'hindrance to operations': extracts from the...</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>Hughes' instant hit buoys Blues</td>\n",
       "      <td>Jack gets his skates on at ice-cold Alex</td>\n",
       "      <td>Chaos as Maracana builds up for United</td>\n",
       "      <td>Depleted Leicester prevail as Elliott spoils E...</td>\n",
       "      <td>Hungry Spurs sense rich pickings</td>\n",
       "      <td>Gunners so wide of an easy target</td>\n",
       "      <td>...</td>\n",
       "      <td>Flintoff injury piles on woe for England</td>\n",
       "      <td>Hunters threaten Jospin with new battle of the...</td>\n",
       "      <td>Kohl's successor drawn into scandal</td>\n",
       "      <td>The difference between men and women</td>\n",
       "      <td>Sara Denver, nurse turned solicitor</td>\n",
       "      <td>Diana's landmine crusade put Tories in a panic</td>\n",
       "      <td>Yeltsin's resignation caught opposition flat-f...</td>\n",
       "      <td>Russian roulette</td>\n",
       "      <td>Sold out</td>\n",
       "      <td>Recovering a title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>Scorecard</td>\n",
       "      <td>The best lake scene</td>\n",
       "      <td>Leader: German sleaze inquiry</td>\n",
       "      <td>Cheerio, boyo</td>\n",
       "      <td>The main recommendations</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>Has Cubie killed fees?</td>\n",
       "      <td>...</td>\n",
       "      <td>On the critical list</td>\n",
       "      <td>The timing of their lives</td>\n",
       "      <td>Dear doctor</td>\n",
       "      <td>Irish court halts IRA man's extradition to Nor...</td>\n",
       "      <td>Burundi peace initiative fades after rebels re...</td>\n",
       "      <td>PE points the way forward to the ECB</td>\n",
       "      <td>Campaigners keep up pressure on Nazi war crime...</td>\n",
       "      <td>Jane Ratcliffe</td>\n",
       "      <td>Yet more things you wouldn't know without the ...</td>\n",
       "      <td>Millennium bug fails to bite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>Coventry caught on counter by Flo</td>\n",
       "      <td>United's rivals on the road to Rio</td>\n",
       "      <td>Thatcher issues defence before trial by video</td>\n",
       "      <td>Police help Smith lay down the law at Everton</td>\n",
       "      <td>Tale of Trautmann bears two more retellings</td>\n",
       "      <td>England on the rack</td>\n",
       "      <td>Pakistan retaliate with call for video of Walsh</td>\n",
       "      <td>Cullinan continues his Cape monopoly</td>\n",
       "      <td>...</td>\n",
       "      <td>South Melbourne (Australia)</td>\n",
       "      <td>Necaxa (Mexico)</td>\n",
       "      <td>Real Madrid (Spain)</td>\n",
       "      <td>Raja Casablanca (Morocco)</td>\n",
       "      <td>Corinthians (Brazil)</td>\n",
       "      <td>Tony's pet project</td>\n",
       "      <td>Al Nassr (Saudi Arabia)</td>\n",
       "      <td>Ideal Holmes show</td>\n",
       "      <td>Pinochet leaves hospital after tests</td>\n",
       "      <td>Useful links</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilgrim knows how to progress</td>\n",
       "      <td>Thatcher facing ban</td>\n",
       "      <td>McIlroy calls for Irish fighting spirit</td>\n",
       "      <td>Leicester bin stadium blueprint</td>\n",
       "      <td>United braced for Mexican wave</td>\n",
       "      <td>Auntie back in fashion, even if the dress look...</td>\n",
       "      <td>Shoaib appeal goes to the top</td>\n",
       "      <td>Hussain hurt by 'shambles' but lays blame on e...</td>\n",
       "      <td>...</td>\n",
       "      <td>Putin admits Yeltsin quit to give him a head s...</td>\n",
       "      <td>BBC worst hit as digital TV begins to bite</td>\n",
       "      <td>How much can you pay for...</td>\n",
       "      <td>Christmas glitches</td>\n",
       "      <td>Upending a table, Chopping a line and Scoring ...</td>\n",
       "      <td>Scientific evidence 'unreliable', defence claims</td>\n",
       "      <td>Fusco wins judicial review in extradition case</td>\n",
       "      <td>Rebels thwart Russian advance</td>\n",
       "      <td>Blair orders shake-up of failing NHS</td>\n",
       "      <td>Lessons of law's hard heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>1</td>\n",
       "      <td>Hitches and Horlocks</td>\n",
       "      <td>Beckham off but United survive</td>\n",
       "      <td>Breast cancer screening</td>\n",
       "      <td>Alan Parker</td>\n",
       "      <td>Guardian readers: are you all whingers?</td>\n",
       "      <td>Hollywood Beyond</td>\n",
       "      <td>Ashes and diamonds</td>\n",
       "      <td>Whingers - a formidable minority</td>\n",
       "      <td>...</td>\n",
       "      <td>Most everywhere:  UDIs</td>\n",
       "      <td>Most wanted:  Chloe lunettes</td>\n",
       "      <td>Return of the cane 'completely off the agenda'</td>\n",
       "      <td>From Sleepy Hollow to Greeneland</td>\n",
       "      <td>Blunkett outlines vision for over 11s</td>\n",
       "      <td>Embattled Dobson attacks 'play now, pay later'...</td>\n",
       "      <td>Doom and the Dome</td>\n",
       "      <td>What is the north-south divide?</td>\n",
       "      <td>Aitken released from jail</td>\n",
       "      <td>Gone aloft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                                               Top1  \\\n",
       "0  2000-01-03      0  A 'hindrance to operations': extracts from the...   \n",
       "1  2000-01-04      0                                          Scorecard   \n",
       "2  2000-01-05      0                  Coventry caught on counter by Flo   \n",
       "3  2000-01-06      1                      Pilgrim knows how to progress   \n",
       "4  2000-01-07      1                               Hitches and Horlocks   \n",
       "\n",
       "                                 Top2  \\\n",
       "0                           Scorecard   \n",
       "1                 The best lake scene   \n",
       "2  United's rivals on the road to Rio   \n",
       "3                 Thatcher facing ban   \n",
       "4      Beckham off but United survive   \n",
       "\n",
       "                                            Top3  \\\n",
       "0                Hughes' instant hit buoys Blues   \n",
       "1                  Leader: German sleaze inquiry   \n",
       "2  Thatcher issues defence before trial by video   \n",
       "3        McIlroy calls for Irish fighting spirit   \n",
       "4                        Breast cancer screening   \n",
       "\n",
       "                                            Top4  \\\n",
       "0       Jack gets his skates on at ice-cold Alex   \n",
       "1                                  Cheerio, boyo   \n",
       "2  Police help Smith lay down the law at Everton   \n",
       "3                Leicester bin stadium blueprint   \n",
       "4                                    Alan Parker   \n",
       "\n",
       "                                          Top5  \\\n",
       "0       Chaos as Maracana builds up for United   \n",
       "1                     The main recommendations   \n",
       "2  Tale of Trautmann bears two more retellings   \n",
       "3               United braced for Mexican wave   \n",
       "4      Guardian readers: are you all whingers?   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  Depleted Leicester prevail as Elliott spoils E...   \n",
       "1                             Has Cubie killed fees?   \n",
       "2                                England on the rack   \n",
       "3  Auntie back in fashion, even if the dress look...   \n",
       "4                                   Hollywood Beyond   \n",
       "\n",
       "                                              Top7  \\\n",
       "0                 Hungry Spurs sense rich pickings   \n",
       "1                           Has Cubie killed fees?   \n",
       "2  Pakistan retaliate with call for video of Walsh   \n",
       "3                    Shoaib appeal goes to the top   \n",
       "4                               Ashes and diamonds   \n",
       "\n",
       "                                                Top8  ...  \\\n",
       "0                  Gunners so wide of an easy target  ...   \n",
       "1                             Has Cubie killed fees?  ...   \n",
       "2               Cullinan continues his Cape monopoly  ...   \n",
       "3  Hussain hurt by 'shambles' but lays blame on e...  ...   \n",
       "4                   Whingers - a formidable minority  ...   \n",
       "\n",
       "                                               Top16  \\\n",
       "0           Flintoff injury piles on woe for England   \n",
       "1                               On the critical list   \n",
       "2                        South Melbourne (Australia)   \n",
       "3  Putin admits Yeltsin quit to give him a head s...   \n",
       "4                             Most everywhere:  UDIs   \n",
       "\n",
       "                                               Top17  \\\n",
       "0  Hunters threaten Jospin with new battle of the...   \n",
       "1                          The timing of their lives   \n",
       "2                                    Necaxa (Mexico)   \n",
       "3         BBC worst hit as digital TV begins to bite   \n",
       "4                       Most wanted:  Chloe lunettes   \n",
       "\n",
       "                                            Top18  \\\n",
       "0             Kohl's successor drawn into scandal   \n",
       "1                                     Dear doctor   \n",
       "2                             Real Madrid (Spain)   \n",
       "3                     How much can you pay for...   \n",
       "4  Return of the cane 'completely off the agenda'   \n",
       "\n",
       "                                               Top19  \\\n",
       "0               The difference between men and women   \n",
       "1  Irish court halts IRA man's extradition to Nor...   \n",
       "2                          Raja Casablanca (Morocco)   \n",
       "3                                 Christmas glitches   \n",
       "4                   From Sleepy Hollow to Greeneland   \n",
       "\n",
       "                                               Top20  \\\n",
       "0                Sara Denver, nurse turned solicitor   \n",
       "1  Burundi peace initiative fades after rebels re...   \n",
       "2                               Corinthians (Brazil)   \n",
       "3  Upending a table, Chopping a line and Scoring ...   \n",
       "4              Blunkett outlines vision for over 11s   \n",
       "\n",
       "                                               Top21  \\\n",
       "0     Diana's landmine crusade put Tories in a panic   \n",
       "1               PE points the way forward to the ECB   \n",
       "2                                 Tony's pet project   \n",
       "3   Scientific evidence 'unreliable', defence claims   \n",
       "4  Embattled Dobson attacks 'play now, pay later'...   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  Yeltsin's resignation caught opposition flat-f...   \n",
       "1  Campaigners keep up pressure on Nazi war crime...   \n",
       "2                            Al Nassr (Saudi Arabia)   \n",
       "3     Fusco wins judicial review in extradition case   \n",
       "4                                  Doom and the Dome   \n",
       "\n",
       "                             Top23  \\\n",
       "0                 Russian roulette   \n",
       "1                   Jane Ratcliffe   \n",
       "2                Ideal Holmes show   \n",
       "3    Rebels thwart Russian advance   \n",
       "4  What is the north-south divide?   \n",
       "\n",
       "                                               Top24  \\\n",
       "0                                           Sold out   \n",
       "1  Yet more things you wouldn't know without the ...   \n",
       "2               Pinochet leaves hospital after tests   \n",
       "3               Blair orders shake-up of failing NHS   \n",
       "4                          Aitken released from jail   \n",
       "\n",
       "                          Top25  \n",
       "0            Recovering a title  \n",
       "1  Millennium bug fails to bite  \n",
       "2                  Useful links  \n",
       "3   Lessons of law's hard heart  \n",
       "4                    Gone aloft  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('Data.csv', encoding = \"ISO-8859-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0fbd9bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4101, 27)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a258623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2166\n",
       "0    1935\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Check whether the class is balanced or not\n",
    "df.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51cbd2d",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5b630e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=df[df.Date<'20150101']\n",
    "test1=df[df.Date>'20141231']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a39b5217",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train1.iloc[:,2:27]\n",
    "test=test1.iloc[:,2:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abd17778",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label=train1.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e66913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label=test1.Label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b1f64",
   "metadata": {},
   "source": [
    "## Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9ab112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.replace(to_replace=\"[^a-zA-Z]\",value=' ',regex=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d1dc9da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.replace(to_replace=\"[^a-zA-Z]\",value=' ',regex=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fcff84",
   "metadata": {},
   "source": [
    "## Converting to Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a83d1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming column names for ease of access\n",
    "list1=[]\n",
    "for i in range(0,25):\n",
    "    list1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d44938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns=list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06cf3f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns=list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "219412c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,25):\n",
    "    train[i]=train[i].str.lower()\n",
    "    test[i]=test[i].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a351fb5",
   "metadata": {},
   "source": [
    "## Combining Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e2799e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = []\n",
    "for row in range(0,len(train.index)):\n",
    "    headlines.append(' '.join(str(x) for x in train.iloc[row,0:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95011e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a  hindrance to operations   extracts from the leaked reports scorecard hughes  instant hit buoys blues jack gets his skates on at ice cold alex chaos as maracana builds up for united depleted leicester prevail as elliott spoils everton s party hungry spurs sense rich pickings gunners so wide of an easy target derby raise a glass to strupar s debut double southgate strikes  leeds pay the penalty hammers hand robson a youthful lesson saints party like it s      wear wolves have turned into lambs stump mike catches testy gough s taunt langer escapes to hit     flintoff injury piles on woe for england hunters threaten jospin with new battle of the somme kohl s successor drawn into scandal the difference between men and women sara denver  nurse turned solicitor diana s landmine crusade put tories in a panic yeltsin s resignation caught opposition flat footed russian roulette sold out recovering a title'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82aeda",
   "metadata": {},
   "source": [
    "# Lemmatizing and removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a898a830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "198ec01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2b1a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8363f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(headlines)):\n",
    "    words=nltk.word_tokenize(headlines[i])\n",
    "    words=[lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    headlines[i]=' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32f90f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hindrance operation extract leaked report scorecard hughes instant hit buoy blue jack get skate ice cold alex chaos maracana build united depleted leicester prevail elliott spoil everton party hungry spur sense rich picking gunner wide easy target derby raise glass strupar debut double southgate strike leeds pay penalty hammer hand robson youthful lesson saint party like wear wolf turned lamb stump mike catch testy gough taunt langer escape hit flintoff injury pile woe england hunter threaten jospin new battle somme kohl successor drawn scandal difference men woman sara denver nurse turned solicitor diana landmine crusade put tory panic yeltsin resignation caught opposition flat footed russian roulette sold recovering title'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f12f79",
   "metadata": {},
   "source": [
    "# Implementing Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "476dfabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "17eae2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "countvector=CountVectorizer(analyzer='word')\n",
    "traindataset=countvector.fit_transform(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7b37a115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3975x40351 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 680443 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f75d9",
   "metadata": {},
   "source": [
    "# Implementing TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f25b1d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e17c268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=TfidfVectorizer(analyzer='word')\n",
    "traindataset_tfidf=cv.fit_transform(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "477a9da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3975x40351 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 680443 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindataset_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04c9b87",
   "metadata": {},
   "source": [
    "# Modeling Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "050520ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0164ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  svm, naive_bayes, neighbors, ensemble\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a922767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(n_jobs=-1)\n",
    "nb_model = naive_bayes.MultinomialNB()\n",
    "svc_model = svm.SVC(probability=True, gamma=\"scale\",)\n",
    "rf_model = ensemble.RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
    "\n",
    "models = [\"lr_model\", \"nb_model\", \"svc_model\", \"rf_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "81547f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model_filter(modellist, X, y):\n",
    "    ''' 1. split the train data further into train and validation (17%). \n",
    "        2. fit the train data into each model of the model list\n",
    "        3. get the classification report based on the model performance on validation data\n",
    "    '''\n",
    "    X_train, X_valid, y_train, y_valid = X[:3471],X[3471:],y[:3471],y[3471:]\n",
    "    for model_name in modellist:\n",
    "        curr_model = eval(model_name)\n",
    "        curr_model.fit(X_train, y_train) \n",
    "        print(f'{model_name} \\n report:{classification_report(y_valid, curr_model.predict(X_valid))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e279c57",
   "metadata": {},
   "source": [
    "## With bag of words embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4130c834",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = traindataset\n",
    "y = train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c078a30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.35      0.42       243\n",
      "           1       0.54      0.70      0.61       261\n",
      "\n",
      "    accuracy                           0.53       504\n",
      "   macro avg       0.53      0.53      0.51       504\n",
      "weighted avg       0.53      0.53      0.52       504\n",
      "\n",
      "nb_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.11      0.17       243\n",
      "           1       0.51      0.85      0.63       261\n",
      "\n",
      "    accuracy                           0.49       504\n",
      "   macro avg       0.45      0.48      0.40       504\n",
      "weighted avg       0.45      0.49      0.41       504\n",
      "\n",
      "svc_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.07      0.12       243\n",
      "           1       0.51      0.91      0.66       261\n",
      "\n",
      "    accuracy                           0.51       504\n",
      "   macro avg       0.47      0.49      0.39       504\n",
      "weighted avg       0.47      0.51      0.40       504\n",
      "\n",
      "rf_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.22      0.29       243\n",
      "           1       0.50      0.73      0.59       261\n",
      "\n",
      "    accuracy                           0.48       504\n",
      "   macro avg       0.46      0.47      0.44       504\n",
      "weighted avg       0.47      0.48      0.45       504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_model_filter(models, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d130b0c2",
   "metadata": {},
   "source": [
    "## With Tfidf Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "70631fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = traindataset_tfidf\n",
    "y = train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fe6eae62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.13      0.20       243\n",
      "           1       0.51      0.85      0.64       261\n",
      "\n",
      "    accuracy                           0.50       504\n",
      "   macro avg       0.48      0.49      0.42       504\n",
      "weighted avg       0.48      0.50      0.43       504\n",
      "\n",
      "nb_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       243\n",
      "           1       0.52      1.00      0.68       261\n",
      "\n",
      "    accuracy                           0.52       504\n",
      "   macro avg       0.26      0.50      0.34       504\n",
      "weighted avg       0.27      0.52      0.35       504\n",
      "\n",
      "svc_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.02      0.04       243\n",
      "           1       0.52      0.99      0.68       261\n",
      "\n",
      "    accuracy                           0.52       504\n",
      "   macro avg       0.62      0.51      0.36       504\n",
      "weighted avg       0.61      0.52      0.37       504\n",
      "\n",
      "rf_model \n",
      " report:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.19      0.26       243\n",
      "           1       0.51      0.79      0.62       261\n",
      "\n",
      "    accuracy                           0.50       504\n",
      "   macro avg       0.48      0.49      0.44       504\n",
      "weighted avg       0.48      0.50      0.45       504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_model_filter(models, X1, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d262ab",
   "metadata": {},
   "source": [
    "### At this stage, lets move forward with Random Forest and Naive Bayes with Bag of words embedding and try to hypertune their parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4284a54",
   "metadata": {},
   "source": [
    "## Hypertuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3240b040",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b0e88666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee080b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MultinomialNB()\n",
    "param={'alpha':[0.0001,0.001,0.01,0.1,1,10,100,1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a7b13eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a4f306ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv=GridSearchCV(model,param_grid=param,n_jobs=-1,scoring='accuracy')\n",
    "gcv.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "927cae88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5275471698113208, MultinomialNB(alpha=100))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.best_score_,gcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "68a22833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=100)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1=MultinomialNB(alpha=100)\n",
    "model1.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06470a5a",
   "metadata": {},
   "source": [
    "### Random Forest with Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "61a4743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1a1f58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_jobs=-1,warm_start=True)\n",
    "param={'n_estimators':[100,200,300],\n",
    "    'criterion':['gini','entropy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c989a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcv=GridSearchCV(model,param_grid=param,n_jobs=-1,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1ee30d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(n_jobs=-1, warm_start=True),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cf2a70be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5122012578616352,\n",
       " RandomForestClassifier(criterion='entropy', n_jobs=-1, warm_start=True))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.best_score_,gcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5ff61e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=200)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RandomForestClassifier(criterion='entropy', n_estimators=200)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7e5146",
   "metadata": {},
   "source": [
    "### Prediction on test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01dac16",
   "metadata": {},
   "source": [
    "First modify the test data by following operations:\n",
    "\n",
    "1. Combine headlines\n",
    "2. Lemmatize and remove stopwords\n",
    "3. Implement bag of words\n",
    "\n",
    "Then predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ce3e4266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining test dataset headlines\n",
    "test_transform= []\n",
    "for row in range(0,len(test.index)):\n",
    "    test_transform.append(' '.join(str(x) for x in test.iloc[row,0:25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6ff64385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize and remove stopwords\n",
    "for i in range(0,len(test_transform)):\n",
    "    words=nltk.word_tokenize(test_transform[i])\n",
    "    words=[lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    test_transform[i]=' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "25c6b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Bag of Words\n",
    "test_dataset = countvector.transform(test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f94fdd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e57b39d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import library to check accuracy\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5d6fab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[149  37]\n",
      " [ 22 170]]\n",
      "0.843915343915344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83       186\n",
      "           1       0.82      0.89      0.85       192\n",
      "\n",
      "    accuracy                           0.84       378\n",
      "   macro avg       0.85      0.84      0.84       378\n",
      "weighted avg       0.85      0.84      0.84       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix=confusion_matrix(test_label,predictions)\n",
    "print(matrix)\n",
    "score=accuracy_score(test_label,predictions)\n",
    "print(score)\n",
    "report=classification_report(test_label,predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d950bee",
   "metadata": {},
   "source": [
    "#### This random forest model gives a very good classification report, lets select this for modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
